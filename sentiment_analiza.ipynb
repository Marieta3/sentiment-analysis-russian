{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analiza.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marieta3/sentiment-analysis-russian/blob/master/sentiment_analiza.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO48X-vVYvqA",
        "colab_type": "text"
      },
      "source": [
        "#Analiza sentimenta tvitova na ruskom jeziku\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wdrXyqYaF3m",
        "colab_type": "text"
      },
      "source": [
        "##Importovanje potrebnih biblioteka"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDhxIyKxYilj",
        "colab_type": "code",
        "outputId": "549e7bb2-2076-4617-e638-50ee4955fb3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tflearn\n",
        "import pandas as pd\n",
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import RussianStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import re\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from tflearn.data_utils import to_categorical"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCqffu4Bxlo1",
        "colab_type": "text"
      },
      "source": [
        "##Konstante"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4ZI_CHOxpN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = 5000\n",
        "MANJI_DEO = True\n",
        "TEST_SIZE = 0.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPmbdnVAbxWy",
        "colab_type": "text"
      },
      "source": [
        "##Učitavanje podataka"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C3wqmvKb0xZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col = 3 #kolona koja sadrzi tvit, ostale kolone nisu potrebne\n",
        "\n",
        "if(MANJI_DEO):\n",
        "  positive = pd.read_csv(\n",
        "      'https://raw.githubusercontent.com/Marieta3/sentiment-analysis-russian/master/positive.csv', header=None, delimiter=';')[[col]].sample(40000);\n",
        "  negative = pd.read_csv(\n",
        "      'https://raw.githubusercontent.com/Marieta3/sentiment-analysis-russian/master/negative.csv', header=None, delimiter=';')[[col]].sample(40000);\n",
        "else:\n",
        "  positive = pd.read_csv(\n",
        "      'https://raw.githubusercontent.com/Marieta3/sentiment-analysis-russian/master/positive.csv', header=None, delimiter=';')[[col]];\n",
        "  negative = pd.read_csv(\n",
        "      'https://raw.githubusercontent.com/Marieta3/sentiment-analysis-russian/master/negative.csv', header=None, delimiter=';')[[col]];  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkZH1Ig3gBAa",
        "colab_type": "text"
      },
      "source": [
        "##Testiranje učitanih podataka\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4QZF7nogJnx",
        "colab_type": "code",
        "outputId": "a43f1382-7fd6-4468-eeec-241ce5017e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('Pozitivnih tvitova: ' +str(len(positive)))\n",
        "print('Negativnih tvitova: ' +str(len(negative)))\n",
        "\n",
        "#positive = positive.head(30000)\n",
        "#negative = negative.head(30000)\n",
        "\n",
        "print('Pozitivnih tvitova: ' +str(len(positive)))\n",
        "print('Negativnih tvitova: ' +str(len(negative)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pozitivnih tvitova: 40000\n",
            "Negativnih tvitova: 40000\n",
            "Pozitivnih tvitova: 40000\n",
            "Negativnih tvitova: 40000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzLm5qPSExXJ",
        "colab_type": "text"
      },
      "source": [
        "##Izvlačenje osnovnog oblika iz tokena"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvVDMhUME2t_",
        "colab_type": "code",
        "outputId": "7640c904-45fe-4cb1-e652-def261cfc934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stemmer = RussianStemmer()\n",
        "stem_cache={}  #smanjuje vreme izvršavanja, ako se reč već pojavljivala, samo je uzmemo iz liste\n",
        "def get_stem(token):\n",
        "  stem =stem_cache.get(token, None)\n",
        "  if stem:\n",
        "    return stem\n",
        "  \n",
        "  token=re.sub('[^а-яА-Я ]', '', token)  #samo slova\n",
        "  stem=stemmer.stem(token)\n",
        "  stem_cache[token]=stem\n",
        "  return stem\n",
        "get_stem('!')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO8j8DF6Fd-l",
        "colab_type": "text"
      },
      "source": [
        "##Tokenizacija"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiWULz3ZFjwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "recnik = Counter()\n",
        "tokenizer = TweetTokenizer()\n",
        "stop_words = stopwords.words('russian')\n",
        "\n",
        "def popuni_recnik(tweets):\n",
        "  for t in tweets.values.tolist():\n",
        "    #print(t[0])\n",
        "    tweet=t[0]\n",
        "    \n",
        "    tokens=tokenizer.tokenize(tweet)\n",
        "    for token in tokens:\n",
        "      stem=get_stem(token)\n",
        "      if stem!='' and stem not in stop_words and token not in stop_words:\n",
        "        recnik[stem]+=1\n",
        "    \n",
        "start_time=datetime.now()  \n",
        "popuni_recnik(positive)\n",
        "popuni_recnik(negative)\n",
        "end_time=datetime.now()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzMO23AKJ3kS",
        "colab_type": "code",
        "outputId": "c721ca29-62b9-4bd3-9f6b-bc8d5042bd59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Потребно време за попуњавање речника: ', end_time-start_time)\n",
        "print(\"Укупан број различитих речи: \", len(recnik))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Потребно време за попуњавање речника:  0:00:39.033091\n",
            "Укупан број различитих речи:  50340\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbbGM9-N_AOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = sorted(recnik, key=recnik.get, reverse=True)[:VOCAB_SIZE]  #сортирано по броју понављања опадајуће, првих 5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_d71VU5_D7v",
        "colab_type": "code",
        "outputId": "9bf44a86-d431-45c4-d553-772877f3e120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print(vocab[:10])\n",
        "print(vocab[1000:1020])\n",
        "print(vocab[-10:])\n",
        "print(\"Дужина скраћеног речника: \",len(vocab))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['эт', 'сегодн', 'прост', 'мо', 'хоч', 'очен', 'ден', 'теб', 'год', 'нов']\n",
            "['клуб', 'дух', 'карт', 'ю', 'добав', 'завид', 'дает', 'поезд', 'везет', 'золот', 'зовут', 'брос', 'вкус', 'мнен', 'возвраща', 'жил', 'стен', 'пипец', 'однак', 'хз']\n",
            "['маразм', 'блях', 'отб', 'вока', 'штол', 'стрим', 'форсаж', 'скушн', 'крыс', 'безразличн']\n",
            "Дужина скраћеног речника:  5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BeRDDPX23AF",
        "colab_type": "code",
        "outputId": "9f703a92-09cb-4324-a82b-6489954d3c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "idx=5000-1\n",
        "print(\"Reč: \", vocab[idx], \" se pojavila \", recnik.get(vocab[idx]), \" puta\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reč:  безразличн  se pojavila  12  puta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLfWZLklXSCC",
        "colab_type": "code",
        "outputId": "17fa988b-f503-4a09-afc9-a0d244928ff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "token_to_idx = {vocab[i] : i for i in range(VOCAB_SIZE)}\n",
        "print(token_to_idx.get('', None))\n",
        "print(type(token_to_idx))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "<class 'dict'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNEcvknB8TgQ",
        "colab_type": "text"
      },
      "source": [
        "##Pretvaranje tvita u vektor\n",
        "\n",
        "*   vektor je duzine broja reci u recniku (5000)\n",
        "*   ukoliko tvit sadrzi rec koja se nalazi u recniku, na odgovarajucem mestu u vektoru se nalazi jedinica; u suprotnom nula\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcANZxS28Qh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tweet_to_vector(tweet, print_unknown=False):\n",
        "  vector=np.zeros(VOCAB_SIZE, dtype=int)\n",
        "  for token in tokenizer.tokenize(tweet):\n",
        "    stem=get_stem(token)\n",
        "    idx=token_to_idx.get(stem, None)\n",
        "    if idx is not None:\n",
        "      vector[idx]=1\n",
        "    else:\n",
        "      if(print_unknown):\n",
        "        print('Nepoznata rec: ', token)\n",
        "  return vector\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZTSxwSJ9a7Y",
        "colab_type": "code",
        "outputId": "fb3f812c-1cf6-49b0-95c7-3ffcbd8a0255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "tw_idx=1\n",
        "pos_tws=positive.values.tolist()\n",
        "neg_tws=negative.values.tolist()\n",
        "print(\"tweet: {}\".format(pos_tws[tw_idx][0]))\n",
        "print(\"tweet: {}\".format(tweet_to_vector(pos_tws[tw_idx][0])[:10]))\n",
        "print(\"tweet: {}\".format(neg_tws[tw_idx][0]))\n",
        "print(\"tweet: {}\".format(tweet_to_vector(neg_tws[tw_idx][0])[:10]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tweet: Представь такую ситуацию,у тебя есть дома кот как ты его назовешь ?)) — Себастьян :3 http://t.co/emLE8R1xbl\n",
            "tweet: [0 0 0 0 0 0 0 1 0 0]\n",
            "tweet: RT @tina_kandelaki: Господи, поколение 20-25 дико инфантильное. Не думала, что буду ворчать, как бабка. Но, by the way(\n",
            "tweet: [0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS5izeQ1rOK2",
        "colab_type": "code",
        "outputId": "21e480dd-a8cf-4bc5-a444-8c9c27c97ae4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  del train_vectors\n",
        "  del test_vectors\n",
        "except:\n",
        "  print('Nije definisano')\n",
        "  \n",
        "train_size = round((len(negative) + len(positive))*(1-TEST_SIZE))\n",
        "test_size = len(negative) + len(positive) - train_size\n",
        "\n",
        "train_vectors = np.zeros((train_size, VOCAB_SIZE), dtype=np.int_)\n",
        "test_vectors = np.zeros((test_size, VOCAB_SIZE), dtype=np.int_)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nije definisano\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwcRRrxXD05C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets=[]\n",
        "cnt=0\n",
        "cnt2=0\n",
        "\n",
        "train_pos_size = round(len(positive)*(1-TEST_SIZE))\n",
        "train_neg_size = round(len(negative)*(1-TEST_SIZE))\n",
        "\n",
        "for tweet in negative.values.tolist():\n",
        "  #print(tweet[0])\n",
        "  tweets.append(tweet[0])\n",
        "  if cnt < train_neg_size:\n",
        "    train_vectors[cnt]=tweet_to_vector(tweet[0])\n",
        "    cnt+=1\n",
        "  else:\n",
        "    test_vectors[cnt2]=tweet_to_vector(tweet[0])\n",
        "    cnt2+=1\n",
        "for tweet in positive.values.tolist():\n",
        "  tweets.append(tweet[0])\n",
        "  if cnt < train_neg_size + train_pos_size:\n",
        "    train_vectors[cnt]=tweet_to_vector(tweet[0])\n",
        "    cnt+=1\n",
        "  else:\n",
        "    test_vectors[cnt2]=tweet_to_vector(tweet[0])\n",
        "    cnt2+=1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnjMgroLOcx8",
        "colab_type": "code",
        "outputId": "959bd745-6e61-43ca-ded3-232fd364a0ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(len(train_vectors))\n",
        "print(len(train_vectors[0]))\n",
        "print(train_vectors)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56000\n",
            "5000\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq5YN7JDKsdd",
        "colab_type": "text"
      },
      "source": [
        "##Brisanje vektora tvitova"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4Z9BNN-70jM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del train_vectors\n",
        "del test_vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXCdZAaqK2tj",
        "colab_type": "text"
      },
      "source": [
        "##Labele"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z1l3gvGEH9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#labels = np.append(np.zeros(len(negative), dtype=np.int_), np.ones(len(positive), dtype=np.int_))\n",
        "\n",
        "train_labels = np.append(\n",
        "    np.zeros(train_neg_size, dtype=np.int_), \n",
        "    np.ones(train_pos_size, dtype=np.int_))\n",
        "\n",
        "test_labels = np.append(\n",
        "    np.zeros(len(negative) - train_neg_size, dtype=np.int_), \n",
        "    np.ones(len(positive) - train_pos_size, dtype=np.int_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NtHGCL2wXhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(train_labels, 2)\n",
        "y_test = to_categorical(test_labels, 2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMYqzARpwmOX",
        "colab_type": "text"
      },
      "source": [
        "##Kreiranje modela"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1meOTMhwoQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(learning_rate=0.1):\n",
        "    tf.reset_default_graph()\n",
        "    \n",
        "    net = tflearn.input_data([None, VOCAB_SIZE])\n",
        "    net = tflearn.fully_connected(net, 125, activation='ReLU')\n",
        "    net = tflearn.fully_connected(net, 25, activation='ReLU')\n",
        "    net = tflearn.fully_connected(net, 2, activation='softmax')\n",
        "    regression = tflearn.regression(\n",
        "        net, \n",
        "        optimizer='sgd', \n",
        "        learning_rate=learning_rate, \n",
        "        loss='categorical_crossentropy')\n",
        "    \n",
        "    model = tflearn.DNN(net)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7-OoTVww4Ov",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "00ce27dd-f9f6-479e-83d7-1566ab57ecad"
      },
      "source": [
        "\n",
        "model = build_model(learning_rate=0.75)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0703 09:28:03.335266 140634864326528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tflearn/layers/core.py:81: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0703 09:28:03.342907 140634864326528 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tflearn/initializations.py:174: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0703 09:28:03.406377 140634864326528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tflearn/optimizers.py:135: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "W0703 09:28:03.421644 140634864326528 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tflearn/objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "W0703 09:28:03.524008 140634864326528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tflearn/summaries.py:46: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0703 09:28:03.615518 140634864326528 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0703 09:28:03.703116 140634864326528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tflearn/helpers/trainer.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teB6f76gw6wF",
        "colab_type": "code",
        "outputId": "0b0d3a8d-c566-4243-93c9-26eee3e2f54b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model.fit(\n",
        "    train_vectors, \n",
        "    y_train, \n",
        "    validation_set=0.1, \n",
        "    show_metric=True, \n",
        "    batch_size=128, \n",
        "    n_epoch=4)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 11819  | total loss: \u001b[1m\u001b[32m0.03651\u001b[0m\u001b[0m | time: 8.328s\n",
            "| SGD | epoch: 030 | loss: 0.03651 - acc: 0.9839 -- iter: 50304/50400\n",
            "Training Step: 11820  | total loss: \u001b[1m\u001b[32m0.03669\u001b[0m\u001b[0m | time: 9.396s\n",
            "| SGD | epoch: 030 | loss: 0.03669 - acc: 0.9847 | val_loss: 0.05866 - val_acc: 0.9780 -- iter: 50400/50400\n",
            "--\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw3DzYX0L2pB",
        "colab_type": "text"
      },
      "source": [
        "##Testiranje"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnAHUYihL5nY",
        "colab_type": "code",
        "outputId": "4e7d4369-e74e-41f0-e4e3-855758cfa3cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions = (np.array(model.predict(test_vectors))[:,0] >= 0.5).astype(np.int_)\n",
        "accuracy = np.mean(predictions == y_test[:,0], axis=0)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.67875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYZf3eQbMJ-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_tweet(tweet):\n",
        "    tweet_vector = tweet_to_vector(tweet, False)\n",
        "    positive_prob = model.predict([tweet_vector])[0][1]\n",
        "    print('Original tweet: {}'.format(tweet))\n",
        "    print('P(positive) = {:.5f}. Result: '.format(positive_prob), \n",
        "          'Positive' if positive_prob > 0.5 else 'Negative')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X14m0BQMTll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_tweet_number(idx):\n",
        "    test_tweet(tweets[idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEN8skJoMVR9",
        "colab_type": "code",
        "outputId": "077d046e-0ff8-4543-d5ee-1632c2d26772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "test_tweet_number(40003)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original tweet: #Ёлки3 А во-вторых,ну чего Самары-то так мало?)вот этим прямо вообще не довольна.тут ооочень много снимали,получается все труды на смарку!\n",
            "P(positive) = 0.99997. Result:  Positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpqrVsT1NsGT",
        "colab_type": "text"
      },
      "source": [
        "##Proba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpb2TgrJNvCq",
        "colab_type": "code",
        "outputId": "afd6b44e-1e3c-4a7d-f80a-12d04f805617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "source": [
        "tweets_for_testing = [\n",
        "    \"меня оштрафовали по дороге домой!\",\n",
        "    \"Я люблю мороженое!\",\n",
        "    \"Я не люблю мороженое\",\n",
        "    \"меня обманули\",\n",
        "    \"меня обманули позитив\",\n",
        "    \"меня он очень бесить\",\n",
        "    \"меня он не бесить\",\n",
        "    \"Почему по ночам мне не спится? У машины скрипит колесо. Отразилась луна в ягодице. 10 лет тебе,синяя птица! Жаль,что букв всего лишь сто со\",\n",
        "    \"Смотрите сегодня, в 23:35, сразу после финала #голос6 @voice1tv, на @1tv, большой новогодний выпуск @vecherniy_urgant #вечернийургант! Я, @urgantcom и @lazarevsergey приготовили для вас праздничный новогодний номер!))) #иванургант #сергейлазарев #билан #… http://ift.tt/2zLgzWk \",\n",
        "    \"ШОК! Данилу Козловского задержали в центре Москвы за чтение Шекспира!\",\n",
        "    \"Через час в Петербурге,на улице Рубинштейна,дом 23 откроют памятник Сергею Довлатову.Надеваем халаты,тапочки,берем собак и цветы!\",\n",
        "    \"Спасибо академикам,коллегам и номинантам!Спасибо всей команде ВУ!Спасибо моей семье!И конечно спасибо Вам,дорогие телезрители!#тэфи2016\",\n",
        "    \"А вот и ласточка-новостнуха!24 апреля в Крокусе я поделюсь с Вами инсайтом на Synergy Insight Forum. Приходите что ли! #sif2017\"\n",
        "]\n",
        "for tweet in tweets_for_testing:\n",
        "    test_tweet(tweet) \n",
        "    print(\"---------\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original tweet: меня оштрафовали по дороге домой!\n",
            "P(positive) = 0.97827. Result:  Positive\n",
            "---------\n",
            "Original tweet: Я люблю мороженое!\n",
            "P(positive) = 0.23612. Result:  Negative\n",
            "---------\n",
            "Original tweet: Я не люблю мороженое\n",
            "P(positive) = 0.23612. Result:  Negative\n",
            "---------\n",
            "Original tweet: меня обманули\n",
            "P(positive) = 0.16907. Result:  Negative\n",
            "---------\n",
            "Original tweet: меня обманули позитив\n",
            "P(positive) = 0.74244. Result:  Positive\n",
            "---------\n",
            "Original tweet: меня он очень бесить\n",
            "P(positive) = 0.00003. Result:  Negative\n",
            "---------\n",
            "Original tweet: меня он не бесить\n",
            "P(positive) = 0.00032. Result:  Negative\n",
            "---------\n",
            "Original tweet: Почему по ночам мне не спится? У машины скрипит колесо. Отразилась луна в ягодице. 10 лет тебе,синяя птица! Жаль,что букв всего лишь сто со\n",
            "P(positive) = 0.00014. Result:  Negative\n",
            "---------\n",
            "Original tweet: Смотрите сегодня, в 23:35, сразу после финала #голос6 @voice1tv, на @1tv, большой новогодний выпуск @vecherniy_urgant #вечернийургант! Я, @urgantcom и @lazarevsergey приготовили для вас праздничный новогодний номер!))) #иванургант #сергейлазарев #билан #… http://ift.tt/2zLgzWk \n",
            "P(positive) = 1.00000. Result:  Positive\n",
            "---------\n",
            "Original tweet: ШОК! Данилу Козловского задержали в центре Москвы за чтение Шекспира!\n",
            "P(positive) = 0.00069. Result:  Negative\n",
            "---------\n",
            "Original tweet: Через час в Петербурге,на улице Рубинштейна,дом 23 откроют памятник Сергею Довлатову.Надеваем халаты,тапочки,берем собак и цветы!\n",
            "P(positive) = 0.99997. Result:  Positive\n",
            "---------\n",
            "Original tweet: Спасибо академикам,коллегам и номинантам!Спасибо всей команде ВУ!Спасибо моей семье!И конечно спасибо Вам,дорогие телезрители!#тэфи2016\n",
            "P(positive) = 0.99986. Result:  Positive\n",
            "---------\n",
            "Original tweet: А вот и ласточка-новостнуха!24 апреля в Крокусе я поделюсь с Вами инсайтом на Synergy Insight Forum. Приходите что ли! #sif2017\n",
            "P(positive) = 0.14639. Result:  Negative\n",
            "---------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}